##first we will login to the third machine or the worker node and create a folder 
  sudo -i
   
   37  mkdir /mnt/data
#############################################
  #lets do all the other activity from the second machine or the master node
  ###we will create a persistent volume 
  [root@ip-172-31-115-211 ~]$ nano pv.yml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: task-pv 
spec:
  capacity:
    storage: 5Gi
  volumeMode: Filesystem #it will look for the filesystem 
  accessModes:
    - ReadWriteOnce #read #readwritemany
  #persistentVolumeReclaimPolicy: Recycle #immedate 
  storageClassName: slow
  hostPath:
    path: "/mnt/data" #this is the path in the host machine where the data will be stored

[root@ip-172-31-115-211 ~]$ kubectl apply -f pv.yml
persistentvolume/task-pv created
[root@ip-172-31-115-211 ~]$ kubectl get pv
NAME      CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE
task-pv   5Gi        RWO            Retain           Available           slow           <unset>                          5s
[root@ip-172-31-115-211 ~]$

      ###lets create the pvc
  [root@ip-172-31-115-211 ~]$ nano pvc.yml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: task-pv-claim
spec:
  resources:
    requests:
      storage: 5Gi
  storageClassName: slow #this storage class name match with the pvc class name
  volumeMode: Filesystem
  accessModes:
    - ReadWriteOnce

[root@ip-172-31-115-211 ~]$ kubectl apply -f pvc.yml
persistentvolumeclaim/task-pv-claim created
      #now again you check the pv it will show the status as bound 
[root@ip-172-31-115-211 ~]$ kubectl get pv
NAME      CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                   STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE
task-pv   5Gi        RWO            Retain           Bound    default/task-pv-claim   slow           <unset>                          2m43s
[root@ip-172-31-115-211 ~]$ kubectl get pvc
NAME            STATUS   VOLUME    CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE
task-pv-claim   Bound    task-pv   5Gi        RWO            slow           <unset>                 22s
[root@ip-172-31-115-211 ~]$

#[root@ip-172-31-115-211 ~]$ nano secret.yml
apiVersion: v1
kind: Secret
metadata:
  name: mysql-db-password
type: Opaque #it will store the secret in a base64 encoded format
data:
  dbpass: ZGJwYXNzd29yZDEx

[root@ip-172-31-115-211 ~]$ kubectl apply -f secret.yml
secret/mysql-db-password created
[root@ip-172-31-115-211 ~]$ kubectl get secret
NAME                TYPE     DATA   AGE
mysql-db-password   Opaque   1      6s
[root@ip-172-31-115-211 ~]$ kubectl describe secret mysql-db-password
Name:         mysql-db-password
Namespace:    default
Labels:       <none>
Annotations:  <none>

Type:  Opaque

Data
====
dbpass:  12 bytes
#next we will create configmap
[root@ip-172-31-115-211 ~]$ nano configmap.yml
apiVersion: v1 
kind: ConfigMap
metadata:
  name: usermanagement-db-script
data:
  mysql_usermgmt.sql: | 
    DROP DATABASE IF EXISTS webappdb;
    CREATE DATABASE webappdb;
    
[root@ip-172-31-115-211 ~]$ kubectl apply -f configmap.yml
configmap/usermanagement-db-script created
###lets check the configmap
[root@ip-172-31-115-211 ~]$ kubectl describe configmap usermanagement-db-script
Name:         usermanagement-db-script
Namespace:    default
Labels:       <none>
Annotations:  <none>

Data
====
mysql_usermgmt.sql:
----
DROP DATABASE IF EXISTS webappdb;
CREATE DATABASE webappdb;

##you will see that in configmap whatever data we have put it is visible. 

[root@ip-172-31-115-211 ~]$ nano mysql.yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mysql 
spec:
  selector:
    matchLabels:
      app: mysql 
  template:
    metadata:
      labels:
        app: mysql 
    spec:
      containers:
      - name: mysql 
        image: mysql:5.6
        env:
        - name: MYSQL_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mysql-db-password #this is the name of the secret we create
              key: dbpass #in the secret file we have the key as dbpass
        volumeMounts: #it is inside the container
        - name: mysql-volume 
          mountPath: /var/lib/mysql 
        - name: db-script 
          mountPath: /docker-entrypoint-initdb.d #this is the path 

        
        ports:
        - containerPort: 3306
      volumes: #it is outside the container
      - name: mysql-volume
        persistentVolumeClaim:
          claimName: task-pv-claim #ame of the persistent volume claim we create
      - name: db-script 
        configMap:
          name: usermanagement-db-script #we create
[root@ip-172-31-115-211 ~]$ kubectl apply -f mysql.yml
deployment.apps/mysql created
[root@ip-172-31-115-211 ~]$
###lets verify the same 
[root@ip-172-31-115-211 ~]$ kubectl get deploy
NAME    READY   UP-TO-DATE   AVAILABLE   AGE
mysql   1/1     1            1           52s
[root@ip-172-31-115-211 ~]$ kubectl get pod
NAME                     READY   STATUS    RESTARTS       AGE

mysql-55744bfbb6-7tbbc   1/1     Running   0              56s
[root@ip-172-31-115-211 ~]$
###lets login inside the pod you need to change the pod id as per your id 
[root@ip-172-31-115-211 ~]$ kubectl exec -it mysql-55744bfbb6-7tbbc -- /bin/bash
root@mysql-55744bfbb6-7tbbc:/#
##lets login inside mysql database password will be dbpassword11
root@mysql-55744bfbb6-7tbbc:/# mysql -u root -p
Enter password:
##once you loged in you need to check the configmap database is created or not 
mysql> show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mysql              |
| performance_schema |
| webappdb  
###finally 
exit
exit
###########lets verify the folder is created on the second machine in /mnt/data
t@ip-172-31-115-227 ~]$ cd /mnt/data
[root@ip-172-31-115-227 data]$ ls
auto.cnf  ib_logfile0  ib_logfile1  ibdata1  mysql  performance_schema  webappdb
[root@ip-172-31-115-227 data]$





